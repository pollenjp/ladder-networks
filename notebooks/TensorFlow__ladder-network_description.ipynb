{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow__ladder-network\n",
    "\n",
    "- 論文\n",
    "  - [Semi-Supervised Learning with Ladder Networks - Antti Rasmus, Harri Valpola, Mikko Honkala, Mathias Berglund, Tapani Raiko](https://arxiv.org/abs/1507.02672)\n",
    "\n",
    "- code\n",
    "  - [rinuboney/ladder](https://github.com/rinuboney/ladder)\n",
    "  - [tarvaina/tensorflow-ladder](https://github.com/tarvaina/tensorflow-ladder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#重要な箇所\" data-toc-modified-id=\"重要な箇所-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>重要な箇所</a></span></li><li><span><a href=\"#End\" data-toc-modified-id=\"End-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>End</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要な箇所"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Valpola (2015) proposed the Ladder network, where the inference process itself can be learned by\n",
    "using the principle of denoising, which has been used in supervised learning (Sietsma and Dow,\n",
    "1991), denoising autoencoders (dAE) (Vincent et al., 2010), and denoising source separation (DSS)\n",
    "(Särelä and Valpola, 2005) for complementary tasks. In dAE, an autoencoder is trained to reconstruct\n",
    "the original observation x from a corrupted version x̃. Learning is based simply on minimizing the\n",
    "norm of the difference of the original x and its reconstruction x̂ from the corrupted $\\tilde{x}$; that is the\n",
    "cost is $||\\tilde{x}-x||^2$ .\n",
    "\n",
    "Valpola は **Ladder network** の推論において, オートエンコーダ(dAE)やソース分割(DSS)による教師あり学習に使われているノイズ除去の考えから発想を得ている. dAEではオリジナルの$x$を, ノイズを加えた$\\tilde{x}$から再構築している. 学習はシンプルでノルムの最小化で表している. $||\\tilde{x}−x||^2$\n",
    "\n",
    "- dAEs are normally only trained to denoise the observations (dAEは普通はラベル付きデータにのみを用いて学習する)\n",
    "\n",
    "> the DSS framework is based on\n",
    "the idea of using denoising functions $\\hat{z} = g(z)$ of the latent variables z to train a mapping z = f (x)\n",
    "which models the likelihood of the latent variables as a function of the observations.\n",
    "\n",
    "DSSでは 観測変数による関数 $\\hat{z}=f(x)$ によって潜在変数$z$のマッピングを学習するために,潜在変数自身を利用してdenoisingを行う. $|| \\hat{z} - z ||^2$. 注意するべきことは$z$は標準化する必要があるということ. でないと $z=\\hat{z}$ という意味のない関数になる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{z} = g( \\tilde{z} )\n",
    "$$\n",
    "\n",
    "- $z$ : 潜在変数\n",
    "- $\\hat{z}$ ; denoised z\n",
    "- $\\tilde{z}$ : noised z (corruption noise)\n",
    "\n",
    "> The shape of the denoising function ($g(\\cdot)$) depends on the distribution of z and the properties of the corruption noise.\n",
    "\n",
    "$||\\hat{z} - z ||$ を最小化させるように学習したdenoising関数($g(\\cdot)$)は入力(corruption noise)Figure1の緑の矢印で表されるところに"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T09:18:12.979682Z",
     "start_time": "2018-09-17T09:18:12.925743Z"
    }
   },
   "source": [
    "![Figure1.png](img/Figure1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$C_d^{(l)} = ||z^{(l)} - \\hat{z}^{(l)}||^2$$\n",
    "$$ \\hat{z}^{(l)} = g \\left( \\tilde{z}^{(l)}, \\hat{z}^{(l+1)} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T09:18:12.979682Z",
     "start_time": "2018-09-17T09:18:12.925743Z"
    }
   },
   "source": [
    "![Figure2.png](img/Figure2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Another feature which differentiates the Ladder network from regular dAEs is that each layer has a skip connection between the encoder and decoder.\n",
    "> This feature **mimics the inference structure of latent variable models** and makes it possible\n",
    "for **the higher levels of the network to leave some of the details for lower levels** to represent.\n",
    "> Rasmus\n",
    "et al. (2015a) showed that such skip connections allow dAEs to focus on abstract invariant features\n",
    "on the higher levels, making the Ladder network a good fit with supervised learning that can select\n",
    "which information is relevant for the task at hand.\n",
    "\n",
    "the Ladder network is a collection of nested denoising autoencoders which share parts of the denoising machinery with each other.\n",
    "\n",
    "Ladder network はお互いに一部の機構を共有しあう、絡みあったdenoisingオートエンコーダの集合\n",
    "\n",
    "!!\n",
    "> In other words, there is **no particular reason** why $\\tilde{z}$ (l+i) as produced by the decoder should resemble\n",
    "the corresponding representations z (l+i) as produced by the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "511px",
    "left": "40px",
    "top": "136px",
    "width": "220px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
